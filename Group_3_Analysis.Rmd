---
title: "Group_3_Analysis"
author: "Group_3"
date: "2023-03-10"
output: html_document
---
# Aim of Analysis

## Data Wrangling
```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#load library
library(dplyr)
library(tidyr)
library(skimr)
library(tidytext)
library(stringr)
library(e1071)
```

```{r Binary output label}
imdb <- read.csv("https://raw.githubusercontent.com/fanghuaqiu/DMML-Group-3/main/group_3.csv",na.strings = "") %>%
  mutate(ROI = (gross-budget)/budget) %>% #define ROI
  mutate(scs = ifelse(ROI>=1,1,0)) %>%
  mutate(content_rating = str_replace(content_rating,"-1","_1")) %>% 
  mutate(title_year = as.factor(title_year),
         aspect_ratio = as.factor((aspect_ratio)),
         scs = as.factor(scs),
         language = as.factor(language),
         content_rating = replace_na(content_rating, "Unknown"),
         country = str_replace(country," ","_"),
         content_rating = str_replace(content_rating," ","_"),
         country = as.factor(country),
         content_rating = as.factor(content_rating),
         color = as.factor(color))#define binary labelled output
```


```{r turn categorical variable to dummy variable}
#Turn genres into matrix
imdb_genre <- imdb[,c("movie_title","genres")] %>%
  mutate(has=1) %>%
  unnest_tokens(genres_c, genres, to_lower=F) %>%
  filter(genres_c != "Fi" & genres_c != "Film") %>%
  group_by(movie_title) %>%
  spread(genres_c,has,fill=0)

#turn categorical variable into dummy variables
dummies <- model.matrix(~color+language+country+title_year+aspect_ratio+content_rating,data=imdb)[,-1]

#Combine datasets, need to adjust for standised data
imdb_dummy <- cbind(imdb,dummies) %>%
    left_join(imdb_genre, by = "movie_title")

```


```{r Separate training, validation and test sets}
same_sample <- function(x,y){
  set.seed(84)
  return(sample(x,y))
}

index_test <- same_sample(1:nrow(imdb), round(0.25*nrow(imdb)))
index_val <- same_sample((1:nrow(imdb))[-index_test], round(0.25*nrow(imdb)))
index_train <- setdiff(1:nrow(imdb),c(index_test,index_val))

test_imdb <- imdb_dummy[index_test,]
valid_imdb <- imdb_dummy[index_val,]
train_imdb <- imdb_dummy[index_train,]
```

# Exploratory Analysis
From figure\ref{fig:cor}

```{r cor, fig.cap="\\label{fig:cor}Correlation of facebook likes"}
library(psych)
pairs.panels(imdb[,c(4,6,8,10,14)])
```


# Modelling

## KNN

## LDA

## Tree

## SVM
## Describe SVM
SVM denotes support vector machines. The main idea of fitting a SVM is trying to find a hyperplane to separate the observations into two parts. The shortest vertical distance from a hyperplane to a point on both sides is called margin. To find an optimal SVM is to find a SVM with the biggest margin. 

## Data wrangling for SVM modelling
First, we have to delete inappropriate variables from the data set. We only keep 
```{r datacleaning for SVM}
## Delete column with constant and we do not need
datacleaning <- function(data,ncol_const){
  data = data[,-c(1,3,5:10,16,17,19,20,25,26,27,29,31:174)]
}
#original datacleaning data = data[,-c(31:152,1,3:10,16,17,19:20,25:27,29,168)], treat all the factor as dummies variable.

train_imdb = datacleaning(train_imdb)
valid_imdb = datacleaning(valid_imdb)
test_imdb = datacleaning(test_imdb)
```

```{r standardize}
## standardize
standard_data <- function(data){
  numerical_vars <- sapply(data,is.numeric)
  var.mean <- apply(data[,numerical_vars],2,mean) 
  var.sd   <- apply(data[,numerical_vars],2,sd)

# standardise training and test sets
  data[,numerical_vars] <-t(apply(data[,numerical_vars], 1, function(x) (x-var.mean)/var.sd))
  return(data)
}
train_imdb = standard_data(train_imdb)
valid_imdb = standard_data(valid_imdb)
test_imdb = standard_data(test_imdb)

```

```{r SVM}
# use for test, delete before final merging
Model <- svm(scs~.,data = train_imdb, type="C-classification", kernel="radial")
summary(Model)
aa2=predict(Model,valid_imdb)
table(valid_imdb$scs,aa2)
length(valid_imdb$scs)
length(aa2)
sum(diag(table(valid_imdb$scs,aa2)))/length(aa2)

## set parameters
cost_range <- c(0.01,0.1,1:10,20)
degree_range <- 2:5
gamma_range <- c(0.001,0.01,0.1,1,10,100)

## Polynomial
SVM_poly <- tune.svm(scs~., data=train_imdb, type="C-classification",
                     kernel="polynomial", cost=cost_range, degree=degree_range)
summary(SVM_poly)
## find the best parameter of poly svm
degree_poly_opt <- SVM_poly$best.parameters[1]
cost_poly_opt <- SVM_poly$best.parameters[2]
## best model of poly svm
SVM_poly_final <- svm(scs~., train_imdb, type="C-classification",
                      kernel="polynomial", degree=degree_poly_opt, cost=cost_poly_opt)
## validate prediction of poly svm
test_poly_pred <- predict(SVM_poly_final,valid_imdb)
table(valid_imdb$scs,test_poly_pred)
sum(diag(table(valid_imdb$scs,test_poly_pred)))/length(valid_imdb$scs)


## Radial
SVM_RBF <- tune.svm(scs~., data=train_imdb, type="C-classification", 
                    kernel="radial", cost=cost_range, gamma=gamma_range)
summary(SVM_RBF)
## find the best parameter of radial svm
gamma_radial_opt <- SVM_RBF$best.parameters[1]
cost_radial_opt <- SVM_RBF$best.parameters[2]
## best model of radial svm
SVM_radial_final <- svm(scs~., train_imdb, type="C-classification", 
                        kernel="radial", gamma=gamma_radial_opt, cost=cost_radial_opt)
## validate prediction of radial svm
test_radial_pred <- predict(SVM_radial_final,valid_imdb)
table(valid_imdb$scs,test_radial_pred)
sum(diag(table(valid_imdb$scs,test_radial_pred)))/length(valid_imdb$scs)

## Linear
SVM_linear <- tune.svm(scs~.,data = train_imdb,type="C-classification",
                       kernel="linear",cost = cost_range,degree = degree_range)
summary(SVM_linear)
## find the best parameter of linear svm
degree_linear_opt <- SVM_linear$best.parameters[1]
cost_linear_opt <- SVM_linear$best.parameters[2]
## best model of linear svm
SVM_linear_final <- svm(scs~., train_imdb, type = "C-classification", 
                        kernel = "linear",cost = cost_linear_opt, degree = degree_linear_opt)
## validate prediction of linear svm
test_linear_pred <- predict(SVM_linear_final,valid_imdb)
table(valid_imdb$scs,test_linear_pred)
sum(diag(table(valid_imdb$scs,test_linear_pred)))/length(valid_imdb$scs)

## sigmoid
SVM_sigmoid <- tune.svm(scs~., data=train_imdb, type="C-classification",
                        kernel="sigmoid", cost=cost_range, gamma=gamma_range)
summary(SVM_sigmoid)
## find the best parameter of sigmoid svm
gamma_sigmoid_opt <- SVM_sigmoid$best.parameters[1]
cost_sigmoid_opt <- SVM_sigmoid$best.parameters[2]
## best model of sigmoid svm
SVM_sigmoid_final <- svm(scs~., train_imdb, type="C-classification",
                         kernel="sigmoid", gamma=gamma_sigmoid_opt, cost=cost_sigmoid_opt)
## validate prediction of sigmoid svm
test_sigmoid_pred <- predict(SVM_sigmoid_final,valid_imdb)
table(valid_imdb$scs,test_sigmoid_pred)
sum(diag(table(valid_imdb$scs,test_sigmoid_pred)))/length(valid_imdb$scs)



#radial preform better, try to use radial SVM to predict
SVM_best1 = SVM_radial_final
predict_final1 = predict(SVM_best1,test_imdb)
table(test_imdb$scs,predict_final1)
sum(diag(table(test_imdb$scs,predict_final1)))/length(test_imdb$scs)

SVM_best2 = SVM_linear_final
predict_final2 = predict(SVM_best2,test_imdb)
table(test_imdb$scs,predict_final2)
sum(diag(table(test_imdb$scs,predict_final2)))/length(test_imdb$scs)


SVM_best3 = SVM_poly_final
predict_final3 = predict(SVM_best3,test_imdb)
table(test_imdb$scs,predict_final3)
sum(diag(table(test_imdb$scs,predict_final3)))/length(test_imdb$scs)


```

##Neural Network

#Conclusion

```


